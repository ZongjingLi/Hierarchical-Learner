{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def build_perception(size,length,device):\n",
    "    edges = [[],[]]\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            # go for all the points on the grid\n",
    "            coord = [i,j];loc = i * size + j\n",
    "            \n",
    "            for r in range(1):\n",
    "                random_long_range = torch.randint(128, (1,2) )[0]\n",
    "                #edges[0].append(random_long_range[0] // size)\n",
    "                #edges[1].append(random_long_range[1] % size)\n",
    "            for dx in range(-length,length+1):\n",
    "                for dy in range(-length,length+1):\n",
    "                    if i+dx < size and i+dx>=0 and j+dy<size and j+dy>=0:\n",
    "                        if (i+dx) * size + (j + dy) != loc:\n",
    "                            edges[0].append(loc)\n",
    "                            edges[1].append( (i+dx) * size + (j + dy))\n",
    "    return torch.tensor(edges).to(device)\n",
    "\n",
    "def grid(width, height):\n",
    "    x = torch.linspace(0,1,width)\n",
    "    y = torch.linspace(0,1,height)\n",
    "    grid_x, grid_y = torch.meshgrid(x, y, indexing='ij')\n",
    "    return torch.cat([grid_x,grid_y], dim = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class RDB_Conv(nn.Module):\n",
    "    def __init__(self, inChannels, growRate, kSize=3):\n",
    "        super(RDB_Conv, self).__init__()\n",
    "        Cin = inChannels\n",
    "        G  = growRate\n",
    "        self.conv = nn.Sequential(*[\n",
    "            nn.Conv2d(Cin, G, kSize, padding=(kSize-1)//2, stride=1),\n",
    "            nn.ReLU(),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return torch.cat((x, out), 1)\n",
    "\n",
    "class RDB(nn.Module):\n",
    "    def __init__(self, growRate0, growRate, nConvLayers, kSize=3):\n",
    "        super(RDB, self).__init__()\n",
    "        G0 = growRate0\n",
    "        G  = growRate\n",
    "        C  = nConvLayers\n",
    "\n",
    "        convs = []\n",
    "        for c in range(C):\n",
    "            convs.append(RDB_Conv(G0 + c*G, G))\n",
    "        self.convs = nn.Sequential(*convs)\n",
    "\n",
    "        # Local Feature Fusion\n",
    "        self.LFF = nn.Conv2d(G0 + C*G, G0, 1, padding=0, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.LFF(self.convs(x)) + x\n",
    "\n",
    "class RDN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(RDN, self).__init__()\n",
    "        self.args = args\n",
    "        r = args.scale[0]\n",
    "        G0 = args.G0\n",
    "        kSize = args.RDNkSize\n",
    "\n",
    "        # number of RDB blocks, conv layers, out channels\n",
    "        self.D, C, G = args.RDNconfig\n",
    "        \"\"\"\n",
    "        {\n",
    "            'A': (20, 6, 32),\n",
    "            'B': (16, 8, 64),\n",
    "        }[args.RDNconfig]\n",
    "        \"\"\"\n",
    "\n",
    "        # Shallow feature extraction net\n",
    "        self.SFENet1 = nn.Conv2d(args.n_colors, G0, kSize, padding=(kSize-1)//2, stride=1)\n",
    "        self.SFENet2 = nn.Conv2d(G0, G0, kSize, padding=(kSize-1)//2, stride=1)\n",
    "\n",
    "        # Redidual dense blocks and dense feature fusion\n",
    "        self.RDBs = nn.ModuleList()\n",
    "        for i in range(self.D):\n",
    "            self.RDBs.append(\n",
    "                RDB(growRate0 = G0, growRate = G, nConvLayers = C)\n",
    "            )\n",
    "\n",
    "        # Global Feature Fusion\n",
    "        self.GFF = nn.Sequential(*[\n",
    "            nn.Conv2d(self.D * G0, G0, 1, padding=0, stride=1),\n",
    "            nn.Conv2d(G0, G0, kSize, padding=(kSize-1)//2, stride=1)\n",
    "        ])\n",
    "\n",
    "        if args.no_upsampling:\n",
    "            self.out_dim = G0\n",
    "        else:\n",
    "            self.out_dim = args.n_colors\n",
    "            # Up-sampling net\n",
    "            if r == 2 or r == 3:\n",
    "                self.UPNet = nn.Sequential(*[\n",
    "                    nn.Conv2d(G0, G * r * r, kSize, padding=(kSize-1)//2, stride=1),\n",
    "                    nn.PixelShuffle(r),\n",
    "                    nn.Conv2d(G, args.n_colors, kSize, padding=(kSize-1)//2, stride=1)\n",
    "                ])\n",
    "            elif r == 4:\n",
    "                self.UPNet = nn.Sequential(*[\n",
    "                    nn.Conv2d(G0, G * 4, kSize, padding=(kSize-1)//2, stride=1),\n",
    "                    nn.PixelShuffle(2),\n",
    "                    nn.Conv2d(G, G * 4, kSize, padding=(kSize-1)//2, stride=1),\n",
    "                    nn.PixelShuffle(2),\n",
    "                    nn.Conv2d(G, args.n_colors, kSize, padding=(kSize-1)//2, stride=1)\n",
    "                ])\n",
    "            else:\n",
    "                raise ValueError(\"scale must be 2 or 3 or 4.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        f__1 = self.SFENet1(x)\n",
    "        x  = self.SFENet2(f__1)\n",
    "\n",
    "        RDBs_out = []\n",
    "        for i in range(self.D):\n",
    "            x = self.RDBs[i](x)\n",
    "            RDBs_out.append(x)\n",
    "\n",
    "        x = self.GFF(torch.cat(RDBs_out,1))\n",
    "        x += f__1\n",
    "\n",
    "        if self.args.no_upsampling:\n",
    "            return x\n",
    "        else:\n",
    "            return self.UPNet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "\n",
    "\n",
    "class GNNSoftPooling(nn.Module):\n",
    "    def __init__(self, output_node_num = 10):\n",
    "        super().__init__()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class ObjectRender(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "\n",
    "class ValkyrNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        device = config.device\n",
    "        # construct the grid domain connection\n",
    "        self.imsize = config.imsize\n",
    "        self.perception_size = config.perception_size\n",
    "        # build the connection graph for the grid domain\n",
    "        self.spatial_coords = grid(self.imsize,self.imsize,device=device)\n",
    "        self.spatial_edges =  build_perception(self.imsize,self.perception_size,device = device)\n",
    "\n",
    "        # [Grid Convs]\n",
    "        conv_feature_dim = config.conv_feature_dim\n",
    "        self.grid_convs =RDN(SimpleNamespace(G0=conv_feature_dim  ,RDNkSize=3,n_colors=3,RDNconfig=(4,3,16),scale=[2],no_upsampling=True))\n",
    "        \n",
    "        # [Diff Pool Construction]\n",
    "        hierarchy_nodes = config.hierarchy_construct\n",
    "        self.diff_pool = nn.ModuleList([\n",
    "            GNNSoftPooling(output_node_num = node_num ) for node_num in hierarchy_nodes\n",
    "        ])\n",
    "\n",
    "        # [Render Fields]\n",
    "        self.render_fields = nn.ModuleList([])\n",
    "\n",
    "        self.conv2object_feature = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from config import *\n",
    "B = 32\n",
    "shuffle = 1\n",
    "dataset = StructureGroundingDataset(config, category=\"vase\", split = \"train\")\n",
    "dataloader = DataLoader(dataset, batch_size = B, shuffle = shuffle)\n",
    "# [Get A Sample Data]\n",
    "for sample in dataloader:\n",
    "    sample, gt = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Visualize Predicate Segmentation]\n",
    "q = \"filter(scene(), container)\"\n",
    "q = \"scene()\"\n",
    "q = model.executor.parse(q)\n",
    "o = model.executor(q, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval(model,dataset):\n",
    "    if not isinstance(dataset,DataLoader):\n",
    "        dataloader = DataLoader(dataset,shuffle = True,batch_size = 4)\n",
    "    else: dataloader = dataset\n",
    "\n",
    "    pt_at = 0\n",
    "    pt_af = 0\n",
    "    pf_at = 0\n",
    "    pf_af = 0\n",
    "\n",
    "    for sample in dataloader:\n",
    "        x,label = sample\n",
    "\n",
    "        prediction,feature,_ = model(x.permute(0,2,1))\n",
    "        cls_num = predict_label.shape[1]\n",
    "        for cls in range(len(cls_num)):\n",
    "          for i in range(label.shape[0]):\n",
    "              predict_label = np.argmax(prediction[i].cpu().detach().numpy())\n",
    "              actual_label = int(label[i])\n",
    "              if predict_label == cls:\n",
    "                  if actual_label == cls:pt_at += 1.\n",
    "                  else:pt_af += 1.\n",
    "\n",
    "              if predict_label != cls:\n",
    "                  if actual_label != cls:pf_at += 1.\n",
    "                  else:pf_af += 1.\n",
    "    accuracy = (pt_at + pt_af) / (pt_at + pt_af + pf_at + pf_af)\n",
    "    precision = pt_at/(pt_at + pf_at)\n",
    "    recall = pt_at/(pt_at + pf_af)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall )\n",
    "    print(\"Raw:{} {} {} {}\".format(pt_at,pt_af,pf_at,pf_af))\n",
    "    print(\"Actual:{} Precision:{} Recall:{} F1:{} \".format(accuracy,\\\n",
    "                            pt_at/(pt_at + pf_at),\\\n",
    "                            pt_at/(pt_at + pf_af),\\\n",
    "                                f1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a47e46093c771f9510c4aabf3710bfb1355e5f870a13f8c22092f45d4d23626d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Melkor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
